{
  "id": "@deeppath-ai/mcp-crew-risk",
  "displayName": "mcp-crew-risk",
  "description": "This framework aims to provide crawler developers and operators with a comprehensive automated compliance detection toolset to evaluate the crawler-friendliness and potential risks of target websites. It covers three major dimensions: legal, social ethics, and technical aspects. Through multi-level risk warnings and specific recommendations, it helps plan crawler strategies reasonably to avoid legal disputes and negative social impacts while improving technical stability and efficiency.",
  "createdAt": "2026-01-17T02:10:17.393Z",
  "links": {
    "homepage": "",
    "registry": "https://smithery.ai/server/@deeppath-ai/mcp-crew-risk"
  },
  "connection": {
    "type": "http",
    "runtime": "node",
    "configSchema": {
      "type": "object",
      "title": "MCP Session Configuration",
      "properties": {
        "server": {
          "type": "object",
          "description": ""
        }
      },
      "description": "Schema for the /mcp endpoint configuration",
      "x-mcp-version": "1.0",
      "x-query-style": "dot+bracket",
      "additionalProperties": false
    }
  },
  "capabilities": [
    {
      "name": "assess-crew-risk",
      "description": "This system evaluates the compliance and potential risks associated with web crawling activities. It is designed to assist developers, legal teams, and data professionals in ensuring that their crawlers operate within acceptable technical, legal, and ethical boundaries."
    }
  ]
}