{
  "id": "@net-service/xpoz",
  "displayName": "xpoz",
  "description": "Social intelligence for AI agents - Twitter/X, Instagram, TikTok data access and insights.\n1.5B+ posts indexed. No API keys, no installation - just add endpoint URL.\n\nPerfect for brand monitoring, competitive analysis, influencer research, and content analysis.\n\n\n\n## Why Xpoz? \n\nðŸš€ **Zero Setup** - No npm install, no Docker, no local dependencies. Add one URL to your config and go.\n\nðŸ”‘ **No API Keys** - no rate limit management required.\n\nðŸ“ **Comprehensive Data** - User profiles, posts, followers, following lists, engagement metrics, and sentiment analysis ready.\n\nðŸ“¤ **CSV Export** - Bulk data export for large-scale analysis and reporting.\n\nðŸ” **OAuth 2.0 Authentication** - Secure Google authentication, no API keys to manage.\n\nðŸ“Š **1.5B+ Posts Indexed** - Including historical data.\n\nâš¡ **Multi-Platform** - Query Twitter/X and Instagram from a single unified interface.\n\n## What You Can Do\n\n**Twitter/X:**\n- Get user profiles, followers, following lists\n- Search tweets by keywords with boolean operators\n- Analyze engagement (comments, quotes, retweets)\n- Export full datasets to CSV\n\n**Instagram:**\n- Look up user profiles and statistics  \n- Search posts by caption keywords\n- Get comments and engagement metrics\n- Analyze follower/following networks\n\n**TikTok**\n- coming soon\n\n## Example Queries\n\nJust ask Claude naturally:\n- \"Get @elonmusk's Twitter profile and recent tweets\"\n- \"Search for tweets about 'artificial intelligence' from last week\"\n- \"Find Instagram posts with #AIart and show engagement stats\"\n- \"Export all tweets mentioning 'OpenAI' to CSV\"\n- \"Compare follower counts between @nvidia and @amd\"\n\n## Use Cases\n\n- Brand monitoring & sentiment analysis\n- Competitive intelligence\n- Influencer research & verification\n- Content trend analysis\n- Social media analytics\n- OSINT research\n\n## MCP Endpoint\n```\nhttps://mcp.xpoz.ai/mcp\n```\n\n## Tags (comma-separated)\n```\ntwitter, instagram, tiktok, social-media, analytics, osint, research, remote, data, intelligence, brand-monitoring, influencer, sentiment-analysis, scraping\n```\n\n## Categories\n```\n  - Social Media\n  - Data & Analytics\n  - Research\n```",
  "createdAt": "2026-01-16T12:53:47.504Z",
  "links": {
    "homepage": "",
    "registry": "https://smithery.ai/server/@net-service/xpoz"
  },
  "connection": {
    "type": "http",
    "runtime": "node",
    "configSchema": {}
  },
  "capabilities": [
    {
      "name": "getTwitterUserById",
      "description": "Get Twitter user profile by numeric ID. Use when you have exact user ID. NOT for username - use getTwitterUserByUsername. Optional fields parameter for performance (default: [\"id\", \"username\", \"name\"]). Available fields: id, username, name, description, location, followersCount, followingCount, verified, profileImageUrl, and more. Returns: id, username, name, bio, followers_count, following_count, tweet_count, created_at, authenticity_score, inauthentic_type."
    },
    {
      "name": "getTwitterUserByUsername",
      "description": "Get user profile by EXACT Twitter handle/username ONLY. CRITICAL: Use ONLY when you have the precise Twitter username (e.g., \"elonmusk\", \"OpenAI\"). DO NOT use for person names (e.g., \"Elon Musk\", \"Sam Altman\") - use searchTwitterUsers instead. DO NOT use for partial matches or fuzzy search - use searchTwitterUsers instead. When to use: User explicitly provides Twitter handle (@username), or you already know exact username from previous context. When NOT to use: Given person's name, searching by name, uncertain about username, need multiple results. Optional fields parameter for performance (default: [\"id\", \"username\", \"name\"]). Available fields: id, username, name, description, location, followersCount, followingCount, verified, profileImageUrl, and more. Returns: single user profile with id, username, name, bio, followers_count, following_count, tweet_count, created_at, authenticity_score, inauthentic_type."
    },
    {
      "name": "searchTwitterUsers",
      "description": "Search users by person name, partial username, or fuzzy match using real-time external API. PRIMARY USE: When given person's name (e.g., \"Elon Musk\", \"Sam Altman\"), partial info, or uncertain username. Use for: Name-based search, finding multiple candidates, fuzzy matching, discovering users. NOT for: Exact username lookup (use getTwitterUserByUsername when username is certain). Optional fields parameter for performance (default: [\"id\", \"username\", \"name\"]). Available fields: id, username, name, description, location, followersCount, followingCount, verified, profileImageUrl, and more. Returns: array of matching users (default 10, max 10) with id, username, name, bio, followers_count."
    },
    {
      "name": "getTwitterFollowers",
      "description": "Get all users that follow a Twitter user (who follows them) with server-side pagination (100 users per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: follower analysis, network graphs, audience demographics, engagement patterns. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows). SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Optional fields parameter for performance (default: [\"id\", \"username\", \"name\"]). Available fields: id, username, name, description, location, followersCount, followingCount, verified, profileImageUrl, and more. DATA FRESHNESS: Automatically checks data age (> 1 week triggers refresh from API). FORCE LATEST: Use sparingly - forceLatest=true bypasses cache for real-time data (increases latency/costs). Returns: results array, count (number of users in response), pagination object (resultsCount, totalPages, totalRows, pageSize, tableName), totalDataCount (actual total followers on Twitter), dataSource. CRITICAL - Understanding totalRows vs totalDataCount: totalRows indicates ONLY what we have in our database. totalDataCount (when present) shows the actual follower count from Twitter. If totalDataCount is missing or undefined, you CANNOT claim totalRows represents all followers - it only shows our partial database data. If totalDataCount > totalRows, we only have partial data. Always check if totalDataCount exists before making claims about total follower counts. Use for: Analyzing follower base, finding connections, building network graphs, audience analysis."
    },
    {
      "name": "getTwitterFollowing",
      "description": "Get all users that a Twitter user is following (who they follow) with server-side pagination (100 users per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: following analysis, network graphs, interest patterns, connection mapping. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows). SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Optional fields parameter for performance (default: [\"id\", \"username\", \"name\"]). Available fields: id, username, name, description, location, followersCount, followingCount, verified, profileImageUrl, and more. DATA FRESHNESS: Automatically checks data age (> 1 week triggers refresh from API). FORCE LATEST: Use sparingly - forceLatest=true bypasses cache for real-time data (increases latency/costs). Returns: results array, count (number of users in response), pagination object (resultsCount, totalPages, totalRows, pageSize, tableName), totalDataCount (actual total following on Twitter), dataSource. CRITICAL - Understanding totalRows vs totalDataCount: totalRows indicates ONLY what we have in our database. totalDataCount (when present) shows the actual following count from Twitter. If totalDataCount is missing or undefined, you CANNOT claim totalRows represents all following accounts - it only shows our partial database data. If totalDataCount > totalRows, we only have partial data. Always check if totalDataCount exists before making claims about total following counts. Use for: Analyzing who users follow, finding connections, building network graphs."
    },
    {
      "name": "getTwitterPostById",
      "description": "Get single Twitter post by numeric ID. First searches database, then external API if not found. Use when you have exact post ID. NOT for search - use getTwitterPostsByKeywords. Optional fields parameter for performance: [\"id\", \"text\", \"retweetCount\"]. Returns: id, text, authorId, createdAt, metrics (retweets, replies, quotes)."
    },
    {
      "name": "getTwitterPostsByAuthorId",
      "description": "Get posts from author by numeric ID with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: statistical analysis, trend detection, data visualization, processing thousands of posts. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Date filters: OMIT startDate/endDate parameters by default to retrieve all posts. ONLY pass these if user explicitly requests specific date range (YYYY-MM-DD format). Optional fields parameter for performance: [\"id\", \"text\", \"createdAt\", \"retweetCount\"]. Returns: results array, count, pagination object, dataDumpExportOperationId for CSV file url. NOT for username - use getTwitterPostsByAuthorUsername."
    },
    {
      "name": "getTwitterPostsByAuthorUsername",
      "description": "Get posts from author by username with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: statistical analysis, trend detection, data visualization, processing thousands of posts. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Date filters: OMIT startDate/endDate parameters by default to retrieve all posts. ONLY pass these if user explicitly requests specific date range (YYYY-MM-DD format). Optional fields parameter for performance: [\"id\", \"text\", \"createdAt\", \"retweetCount\"]. Returns: results array, pagination object, dataDumpExportOperationId for CSV file url. NOT for author ID - use getTwitterPostsByAuthorId."
    },
    {
      "name": "getTwitterPostsByKeywords",
      "description": "Search posts by keywords with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: sentiment analysis, trend detection, content analysis across thousands of posts. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Returns by default: id, text, authorUsername, createdAtDate. First searches database, then external API if data is stale or missing. QUERY SYNTAX: Use double quotes for exact phrase match (e.g., \"artificial intelligence\"). Without quotes, matches any word. ALWAYS use quotes when user requests exact search or specific phrase. Examples: \"machine learning\" (exact), AI crypto (any word), \"climate change\" policy (exact phrase + keyword). Filters: language, authorId/authorUsername. Date filters: OMIT startDate/endDate by default. ONLY pass if user explicitly requests specific date range (YYYY-MM-DD format). FIELDS parameter (optional): Specify to get additional/different fields. Available: Core (id, text, authorId, authorUsername, createdAt), Engagement (retweetCount, replyCount, quoteCount, impressionCount, bookmarkCount), Metadata (lang, source, suspended, deleted), Relations (conversationId, quotedTweetId, retweetedTweetId), Content (hashtags, mentions, mediaUrls), Location (country, region, city). Returns: results array, pagination object, dataDumpExportOperationId for CSV file url."
    },
    {
      "name": "getTwitterPostRetweets",
      "description": "Get retweets of specific post with server-side pagination (100 posts per page, database-only). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full retweet dataset. Ideal for: amplification analysis, reach studies, engagement patterns. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Database-only search for historical retweet data. Date filter: OMIT startDate by default. ONLY pass if user explicitly requests filtering from specific date (YYYY-MM-DD format). Use to analyze post amplification patterns. NOT for quotes - use getTwitterPostQuotes. Optional fields parameter for performance: [\"id\", \"authorUsername\", \"createdAt\"]. Returns: results array, pagination object, dataDumpExportOperationId for CSV file url."
    },
    {
      "name": "getTwitterPostQuotes",
      "description": "Get quote posts of specific post with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze all quote tweets. Ideal for: sentiment analysis on reactions, commentary patterns, viral spread analysis. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). First searches database, then external API if data is stale (>10 days). Date filter: OMIT startDate by default. ONLY pass if user explicitly requests filtering from specific date (YYYY-MM-DD format). Use to analyze commentary on post. NOT for retweets - use getTwitterPostRetweets. Optional fields parameter for performance: [\"id\", \"text\", \"authorUsername\", \"createdAt\"]. Returns: results array, pagination object, dataDumpExportOperationId for CSV file url."
    },
    {
      "name": "getTwitterPostComments",
      "description": "Get comments (replies) to specific post with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze all comments. Ideal for: sentiment analysis, discussion themes, community engagement analysis. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). First searches database, then external API if data is stale (>10 days). Date filter: OMIT startDate by default. ONLY pass if user explicitly requests filtering from specific date (YYYY-MM-DD format). Use to analyze community response and discussion. NOT for quotes - use getTwitterPostQuotes. Optional fields parameter for performance: [\"id\", \"text\", \"authorUsername\", \"createdAt\"]. Returns: results array, pagination object, dataDumpExportOperationId for CSV file url."
    },
    {
      "name": "countTweets",
      "description": "Count tweets containing a specific phrase within a date range. Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. Returns the total count of matching tweets (int), or zero if none found. QUERY SYNTAX: Use double quotes for exact phrase match (e.g., \"climate crisis\"). Without quotes, matches any word. ALWAYS use quotes when user requests exact count or specific phrase. Examples: \"machine learning\" (exact phrase count), bitcoin (any tweet with bitcoin). Filters: date range (startDate/endDate in YYYY-MM-DD). Default: startDate=6 months ago if not provided. Use for analytics and trend analysis without retrieving full tweet data."
    },
    {
      "name": "checkOperationStatus",
      "description": "Check status and retrieve results from background operations. Required: operationId. HANDLES TWO TYPES: (1) Query operations (op_toolname_xxx): returns paginated results + dataDumpExportOperationId. (2) Export operations (op_datadump_xxx): returns S3 signed URL for CSV download. CRITICAL: You MUST keep polling until operation finishes. DO NOT stop until status is completed/failed/cancelled. POLLING LOOP: (1) Call immediately after getting operation ID. (2) If status=running, wait exactly 5 seconds. (3) Call again after 5 seconds. (4) Repeat step 2-3 continuously until status changes to completed/failed/cancelled. (5) Only stop when operation is finished. Returns: For queries - results, pagination, dataDumpExportOperationId. For exports - signedUrl, fileName, totalRows. NEVER make calls without 5 second waits between them."
    },
    {
      "name": "cancelOperation",
      "description": "Cancel running operation. Required: operationId. Gracefully stops operation at next checkpoint. Returns confirmation. Use checkOperationStatus to verify cancellation completed."
    },
    {
      "name": "getInstagramPostById",
      "description": "Get single Instagram post by ID. First searches database, then external API if not found or data is stale (>3 days). Use when you have exact post ID. Optional fields parameter for performance: [\"id\", \"caption\", \"likeCount\"]. Returns: id, caption, userId, username, createdAtDate, engagement metrics (likes, comments, reshares, video plays)."
    },
    {
      "name": "getInstagramPostsByUserId",
      "description": "Get posts by Instagram user ID with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: engagement analysis, content trends, posting patterns across all posts. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Date filters: OMIT startDate/endDate parameters by default to retrieve all posts. ONLY pass these if user explicitly requests specific date range (YYYY-MM-DD format). Optional fields parameter for performance: [\"id\", \"caption\", \"username\", \"createdAtDate\", \"likeCount\"]. Returns: results array, count, pagination object, dataDumpExportOperationId for CSV file url. NOT for username - use getInstagramPostsByUsername."
    },
    {
      "name": "getInstagramPostsByUsername",
      "description": "Get posts by Instagram username with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: engagement analysis, content trends, posting patterns across all posts. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Date filters: OMIT startDate/endDate parameters by default to retrieve all posts. ONLY pass these if user explicitly requests specific date range (YYYY-MM-DD format). Optional fields parameter for performance: [\"id\", \"caption\", \"username\", \"createdAtDate\", \"likeCount\"]. Returns: results array, count, pagination object, dataDumpExportOperationId for CSV file url. NOT for user ID - use getInstagramPostsByUserId."
    },
    {
      "name": "getInstagramPostsByKeywords",
      "description": "Search Instagram posts by keywords with server-side pagination (100 posts per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: content analysis, hashtag trends, brand monitoring across thousands of posts. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). First searches database, then external API if data is stale (>1 week) or no results found. QUERY SYNTAX: Use double quotes for exact phrase match in captions (e.g., \"travel photography\"). Without quotes, matches any word. ALWAYS use quotes when user requests exact search or specific phrase. Examples: \"fashion week\" (exact), travel food (any word), \"sunset beach\" california (exact phrase + keyword). Date filters: OMIT startDate/endDate parameters by default. ONLY pass these if user explicitly requests specific date range (YYYY-MM-DD format). Optional fields parameter for performance: [\"id\", \"caption\", \"username\", \"createdAtDate\", \"likeCount\"]. Returns: results array, count, query, pagination object, dataDumpExportOperationId for CSV file url."
    },
    {
      "name": "getInstagramUserById",
      "description": "Get Instagram user profile by numeric ID. Use when you have exact user ID. NOT for username - use getInstagramUserByUsername. Optional fields parameter for performance (default: [\"id\", \"username\", \"fullName\"]). Available fields: id, username, fullName, biography, isPrivate, isVerified, followerCount, followingCount, mediaCount, profilePicUrl, and more. Returns: userId, username, fullName, followerCount, followingCount, mediaCount, biography, isVerified, isPrivate, profilePicUrl."
    },
    {
      "name": "getInstagramUserByUsername",
      "description": "Get user profile by EXACT Instagram username ONLY. CRITICAL: Use ONLY when you have the precise Instagram username (e.g., \"instagram\", \"cristiano\"). DO NOT use for person names (e.g., \"Cristiano Ronaldo\") - use searchInstagramUsers instead. DO NOT use for partial matches or fuzzy search - use searchInstagramUsers instead. When to use: User explicitly provides Instagram username (@username), or you already know exact username from previous context. When NOT to use: Given person's name, searching by name, uncertain about username, need multiple results. Optional fields parameter for performance (default: [\"id\", \"username\", \"fullName\"]). Available fields: id, username, fullName, biography, isPrivate, isVerified, followerCount, followingCount, mediaCount, profilePicUrl, and more. Returns: single user profile with userId, username, fullName, followerCount, followingCount, mediaCount, biography, isVerified, isPrivate, profilePicUrl."
    },
    {
      "name": "searchInstagramUsers",
      "description": "Search users by person name, partial username, or fuzzy match using real-time external API. PRIMARY USE: When given person's name (e.g., \"Cristiano Ronaldo\", \"Kim Kardashian\"), partial info, or uncertain username. Use for: Name-based search, finding multiple candidates, fuzzy matching, discovering users. NOT for: Exact username lookup (use getInstagramUserByUsername when username is certain). Optional fields parameter for performance (default: [\"id\", \"username\", \"fullName\"]). Available fields: id, username, fullName, biography, isPrivate, isVerified, followerCount, followingCount, mediaCount, profilePicUrl, and more. Returns: array of matching users (default 10, max 10) with userId, username, fullName, followerCount, biography, profilePicUrl."
    },
    {
      "name": "getInstagramFollowers",
      "description": "Get all users that follow an Instagram user (who follows them) with server-side pagination (100 users per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: follower analysis, network graphs, audience demographics, engagement patterns. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows). SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Optional fields parameter for performance (default: [\"id\", \"username\", \"fullName\"]). Available fields: id, username, fullName, biography, isPrivate, isVerified, followerCount, followingCount, mediaCount, profilePicUrl, and more. DATA FRESHNESS: Automatically checks data age (> 1 week triggers refresh from API). FORCE LATEST: Use sparingly - forceLatest=true bypasses cache for real-time data (increases latency/costs). Returns: results array, count (users in current page), pagination object (resultsCount: users in page, totalRows: users in DB, totalPages, pageSize, tableName), totalDataCount (actual total followers on Instagram), dataSource. CRITICAL - Understanding totalRows vs totalDataCount: totalRows indicates ONLY what we have in our database. totalDataCount (when present) shows the actual follower count from Instagram. If totalDataCount is missing or undefined, you CANNOT claim totalRows represents all followers - it only shows our partial database data. If totalDataCount > totalRows, we only have partial data. Always check if totalDataCount exists before making claims about total follower counts. Use for: Analyzing follower base, finding connections, building network graphs, audience analysis."
    },
    {
      "name": "getInstagramFollowing",
      "description": "Get all users that an Instagram user is following (who they follow) with server-side pagination (100 users per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze full dataset without pagination limits. Ideal for: following analysis, network graphs, interest patterns, connection mapping. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows). SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. Cannot pass pageNumber without tableName. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Optional fields parameter for performance (default: [\"id\", \"username\", \"fullName\"]). Available fields: id, username, fullName, biography, isPrivate, isVerified, followerCount, followingCount, mediaCount, profilePicUrl, and more. DATA FRESHNESS: Automatically checks data age (> 1 week triggers refresh from API). FORCE LATEST: Use sparingly - forceLatest=true bypasses cache for real-time data (increases latency/costs). Returns: results array, count (users in current page), pagination object (resultsCount: users in page, totalRows: users in DB, totalPages, pageSize, tableName), totalDataCount (actual total following on Instagram), dataSource. CRITICAL - Understanding totalRows vs totalDataCount: totalRows indicates ONLY what we have in our database. totalDataCount (when present) shows the actual following count from Instagram. If totalDataCount is missing or undefined, you CANNOT claim totalRows represents all following accounts - it only shows our partial database data. If totalDataCount > totalRows, we only have partial data. Always check if totalDataCount exists before making claims about total following counts. Use for: Analyzing who users follow, finding connections, building network graphs."
    },
    {
      "name": "getInstagramCommentsByPostId",
      "description": "Get comments for an Instagram post with server-side pagination (100 comments per page). Returns operation ID - IMMEDIATELY call checkOperationStatus to get results. CRITICAL: Results are ONLY available via checkOperationStatus - do not try other tools or wait for user prompt. CSV EXPORT: Response includes dataDumpExportOperationId for downloading COMPLETE dataset as CSV. Use checkOperationStatus with dataDumpExportOperationId to get S3 download link (ready in ~30-60 seconds). CODE EXECUTION: Download CSV and use code execution to analyze all comments. Ideal for: sentiment analysis, engagement patterns, community feedback analysis. FIRST CALL: Omit pageNumber and tableName. Creates cached table, returns page 1 with pagination metadata (tableName, totalPages, totalRows) plus dataDumpExportOperationId. SUBSEQUENT PAGES: Use tableName from first response with pageNumber (2, 3, etc.) to fetch additional pages. BULK FETCH: Optionally use pageNumberEnd with pageNumber and tableName to fetch multiple consecutive pages at once (e.g., pageNumber=1, pageNumberEnd=5 returns pages 1-5). Date filters: OMIT startDate/endDate parameters by default to retrieve all comments. ONLY pass these if user explicitly requests specific date range (YYYY-MM-DD format). Optional fields parameter for performance: [\"id\", \"text\", \"username\", \"createdAtDate\", \"likeCount\"]. Returns: results array, count, pagination object, dataDumpExportOperationId for CSV file url. Use when you need to retrieve comments for a specific Instagram post by post ID."
    },
    {
      "name": "getUserAccessKey",
      "description": "Retrieve authenticated user access key. Required: authentication, confirmation. Returns: access key, metadata."
    },
    {
      "name": "checkAccessKeyStatus",
      "description": "Check access key status without revealing key. Required: authentication. Returns: status, metadata."
    }
  ]
}